{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ec5a5e-acd7-4f2c-a50f-cf2bf24f5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))  # Ensure it points to your project root\n",
    "\n",
    "from van_code.nn import NeuralVANMultilevel_block_wise\n",
    "from van_code.ising import ising_energy,analytical_solution,local_ising_energy\n",
    "from van_code.montecarlo import *\n",
    "from van_code.utils import *\n",
    "from van_code.obs import Obs\n",
    "from unzip import file_exists_or_unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4569e9-4b9e-4e87-871e-93d83c0511da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device=mps.\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    default_dtype_torch=torch.float32\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'You are using device={device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164be43-0322-4b8c-ae36-a9b0b0e20310",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Model and parameters\n",
    "Our multilevel architecture uses different blocks of Autoregressive neural networks which are based on the VAN architecture by [Wu et al. (2019)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.122.080602)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f18c2f-e4e7-4a4d-81ab-153f60db5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines important parameters for the simulation\n",
    "\n",
    "Lc=2 # defines the coarser lattice\n",
    "beta=0.44 # defines the beta value (inverse of the temperature)\n",
    "\n",
    "# VAN parameters\n",
    "net_depth = 3\n",
    "net_width= 16\n",
    "half_kernel_size =6\n",
    "\n",
    "# Conditional VAN parameters\n",
    "# The i-th element of the list correspond to the parameters associated to the i-th block in the multilevel\n",
    "\n",
    "hidden_size=[[32]] * 10 # Hidden size of each CondVAN\n",
    "kernel_size=[[5,3]] * 10  # Kernel of CondVAN\n",
    "\n",
    "nlevels = 2 # Defines the number of blocks (upsamling step) in the multilevel. Every block doubles the lattice. Example: if the coarser is 2x2 after 3 levels we have 16x16\n",
    "hb_last = True # Whether to use heatbath to sample unbiased configuration from the last ARNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e338fe-3d49-412c-99be-d84c4f7d2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "van_hyp={\n",
    "    'net_depth':net_depth,\n",
    "    'net_width': net_width,\n",
    "    'half_kernel_size':half_kernel_size,\n",
    "    'bias':False,'z2':False,\n",
    "    'res_block':True,\n",
    "    'x_hat_clip':False,\n",
    "    'final_conv':True,\n",
    "    'epsilon':1.e-8,\n",
    "    'device':device\n",
    "}\n",
    "\n",
    "block_net_hyp={\n",
    "    'hidden_size':hidden_size,\n",
    "    'kernel_size':kernel_size,\n",
    "    'epsilon':1e-7,\n",
    "    'level':0,\n",
    "    'device':device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994f246c-3856-4c65-8e2d-106364f5bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_size [[5, 3], [5, 3], [5, 3], [5, 3], [5, 3], [5, 3], [5, 3], [5, 3], [5, 3], [5, 3]]\n",
      "nnot gd 0 [5, 3]\n",
      "1 [5, 3]\n",
      "Lf= 8\n",
      "2 [5, 3]\n",
      "\n",
      "\n",
      "=======================================================================================================================================================\n",
      "\n",
      "You will start from coarser lattices of shape 2x2 and sample finer lattices of resolution 8x8 using 2 multilevel steps.\n",
      "\n",
      "=======================================================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "\n",
    "model = NeuralVANMultilevel_block_wise(\n",
    "    Lc,\n",
    "    van_hyp,\n",
    "    block_net_hyp,\n",
    "    nlevels,\n",
    "    hb_last,\n",
    "    ising_energy,\n",
    "    local_ising_energy,\n",
    "    beta,\n",
    "    device\n",
    ")\n",
    "Lf = model.Lf\n",
    "#print(model)\n",
    "\n",
    "print(f'\\n\\n=======================================================================================================================================================\\n')\n",
    "print(f'You will start from coarser lattices of shape {Lc}x{Lc} and sample finer lattices of resolution {model.Lf}x{model.Lf} using {nlevels} multilevel steps.')\n",
    "print(f'\\n=======================================================================================================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6989f290-fcf4-42e6-8914-e7b658d58175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default parameters for optimizer and scheduler\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.92, patience=1000, min_lr=1e-07)\n",
    "\n",
    "# Define additional training parameters. Arbitrary values can be chosen\n",
    "# the values chosen below are optimized for the purpose of this demo.\n",
    "\n",
    "bs = 16\n",
    "nepochs = 500\n",
    "print_freq = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d9a949d-4642-4a59-a987-2282d0a12854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose main path to store model and logs\n",
    "main_path=''+'../data/'\n",
    "\n",
    "# Creates model identifier with corresponding params\n",
    "# '/Lf'+'_beta'+'_nblocks'+'_PCNNdepth'+'_width'+'_half_ker'+'_CCNNhs'+'_ks'\n",
    "\n",
    "model_id = f'{str(model.Lf)}_{str(beta)}_{str(nlevels)}_{str(net_depth)}_{str(net_width)}_{str(half_kernel_size)}_{str(hidden_size[0][0])}_{str(kernel_size[0])}'\n",
    "\n",
    "lc_path = main_path + 'training/' + model_id\n",
    "h_path = lc_path + '_history.log' # Path to Training history\n",
    "\n",
    "## Dict of paths to store different results\n",
    "\n",
    "res_paths = {\n",
    "    'weights': main_path+ 'model/'+ model_id +'.chckpnt', # models' weights\n",
    "    'sim' : main_path + 'results/' + model_id + '_measures.log',  # Simulations logging\n",
    "    'sim_md' : main_path + 'results/' + model_id + '_measures_modedrop.log',  # Simulations mode dropping\n",
    "    'cluster' : main_path + 'results/' + model_id + '_measuresCluster.log',  # Simulations\n",
    "    'dict_hist' : lc_path + '_historyDict.pkl',  # dictionary learning curve\n",
    "    'mh' : main_path+'results/'+ model_id +'_measuresIMH.log' # neural MCMC sampling results\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee793ae-1622-4070-8627-ca9c012f7914",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ed70f",
   "metadata": {},
   "source": [
    "### In order to do the warm-restart training, the model loads weights of the previous levels (if checkpoint exists). If no weights are available train a new model from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2de395c-9d62-4310-a4e6-3b55f0028563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================================================================\n",
      "\n",
      "Nothing to load. Training of new model... \n",
      "\n",
      "============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Multilevel' object has no attribute 'freeze_all_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNothing to load. Training of new model... \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m============================================================================================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m history=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex_kernel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m save(model, optimizer, res_paths[\u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     19\u001b[39m write(history, lc_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/multilevelTest/van_code/nn.py:710\u001b[39m, in \u001b[36mNeuralVANMultilevel_block_wise.train\u001b[39m\u001b[34m(self, nepochs, batch_size, lr, print_freq, history_path, flex_kernel, on_file)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\n\u001b[32m    700\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    701\u001b[39m         nepochs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    707\u001b[39m         on_file=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    708\u001b[39m ):\n\u001b[32m    709\u001b[39m     \u001b[38;5;28mself\u001b[39m.layers.module.current_level = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfreeze_all_layers\u001b[49m()\n\u001b[32m    711\u001b[39m     history = {\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mvarF\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mvar_varF\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mbetaF\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mESS\u001b[39m\u001b[33m'\u001b[39m: []}\n\u001b[32m    712\u001b[39m     t0 = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/multilevelTest/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1926\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1927\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1929\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1930\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Multilevel' object has no attribute 'freeze_all_layers'"
     ]
    }
   ],
   "source": [
    "if os.path.exists(res_paths['weights'] and res_paths['dict_hist']):\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    print(f\"Loading model {res_paths['weights']}.\")\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    load(model, optimizer, res_paths['weights'])\n",
    "    with open(res_paths['dict_hist'], 'rb') as handle:\n",
    "        history= pickle.load(handle)\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    print(f\"Loading successful!\")\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "\n",
    "else:\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    print(f\"Nothing to load. Training of new model... \")\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "\n",
    "    history=model.train(nepochs, bs, lr, print_freq, h_path, flex_kernel=True, on_file=True)\n",
    "    save(model, optimizer, res_paths['weights'])\n",
    "    write(history, lc_path)\n",
    "\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    print(f\"Training successful!\")\n",
    "    print(f'\\n============================================================================================================================\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a949452-ab47-4670-9245-c646cc7b3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 10 # binning to plot training history.\n",
    "\n",
    "if history:\n",
    "    plt.plot(np.asarray(history['ESS']))\n",
    "    plt.ylabel('ESS')\n",
    "    plt.xlabel('Training steps for the current level')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51a028-9e89-4544-a528-2aa80f57b118",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Analysis: Reverse Metrics\n",
    "This sections includes metrics which require samples from the model, e.g., $s\\sim q_\\theta$ where $q_\\theta$ is the autoregressive neural network.\n",
    "The resulting script `res_paths['sim']` will store:\n",
    "\n",
    "`Loss, FreeEn, ESS_rev, InternalEn, Absmag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba045204-fb9d-4fcd-bfd3-bdadcd951ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "w,E,m,t = model.sample_n_OBS(100,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12ab2f7-55e3-4532-b794-7aac9e3ff4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: ../data/results/8_0.44_2_3_16_6_32_[5, 3]_measures.log\n"
     ]
    }
   ],
   "source": [
    "gamma_analysis(w, res_paths['sim']) # Stores data: Loss, FreeEn, ESS_rev\n",
    "_=gamma_analysis_OBS(E, w, res_paths['sim']) # Stores data: Internal Energy\n",
    "_=gamma_analysis_OBS(np.abs(m), w, res_paths['sim']) # Stores data: Absolute magnetization\n",
    "print(f\"Results saved at: {res_paths['sim']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975e73c-b88e-43c4-bc8c-8f03619da4ba",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Analysis: Forward metrics\n",
    "> Note to user:\n",
    "> - This only works for small lattices. As this is just a demo, configurations for larger lattices (or different $\\beta$) are not provided and users have to generate reference configurations by themselves. Once configurations are available the pipeline below can be used.\n",
    "> - Ensure to unzip the configurations before running the code below.\n",
    "\n",
    "\n",
    "This sections includes metrics which require samples from the true distribution, e.g., $s\\sim p$ where $p$ is the target Boltzmann distribution.\n",
    "Such samples can be obtained with standard methods such as the Cluster method. For the sake of this demo, configs sampled with cluster method are stored in `data/config/Ising_data_nx16_beta0.4400000000_data1000000.dat`.\n",
    "\n",
    "The script `res_paths['sim_md']` will store:\n",
    "\n",
    "`Loss_rev, FreeEn_rev, ESS_rev, Loss_fwd, FreeEn_fwd, ESS_fwd, mode_dropping_est,  InternalEn, Absmag`\n",
    "\n",
    "The script `res_paths['cluster']` will store analysis performed on samples from Cluster method, i.e., $s\\sim p$:\n",
    "\n",
    "`Loss, FreeEn, ESS_rev, InternalEn, Absmag`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005731df-a09d-4a20-b0f5-58b27a7aa453",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndat = 1000000\n",
    "path_ising = main_path + f'config/Ising_data_nx{model.Lf}_beta0.4400000000_data{ndat}.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1190fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ File '../data/config/Ising_data_nx8_beta0.4400000000_data1000000.dat' not found. Unzipping files in '../data/config'...\n",
      "✅ Extracted 'ising4x4.zip'\n",
      "✅ Extracted 'ising8x8.zip'\n",
      "✅ Extracted 'ising16x16.zip'\n",
      "✅ File '../data/config/Ising_data_nx8_beta0.4400000000_data1000000.dat' found after extraction. Continuing...\n"
     ]
    }
   ],
   "source": [
    "file_exists_or_unzip(path_ising,main_path + f'config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0e67ca9-7603-422e-ad35-9c313102d8a4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Loads data for 16x16\n",
    "# N.B. This might take some time.\n",
    "data = np.genfromtxt(path_ising).reshape(-1, Lf, Lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd610b06-1d9b-470c-9d5e-f4af3ad676c4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cluster_analysis(data, ising_energy, beta, res_paths['cluster']) # U, tau |m|, tau |m|\n",
    "print(f\"Results saved at: {res_paths['cluster']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb480693-5a2a-4188-8c17-7a6700b41fc6",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wf = model.sample_from_MCMC(data, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b5abf-1f37-4ddd-bc78-320de50c518e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gamma_analysis_modedrop(w, wf, res_paths['sim_md']) # Stores data: Loss, betaF, ESS, Floss, FbetaF, FESS, modedrop, U, absmag\n",
    "print(f\"Results saved at: {res_paths['sim_md']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f75ad-397a-4db0-b08c-ff0108a0445d",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Independent Metropolis-Hastings\n",
    "\n",
    "The cells below run Neural MCMC using a Metropolis Hastings accept-reject steps to unbias the samples drawn from the model as proposed in [Nicoli et al. Phys. Rev. E (2020)](https://link.aps.org/accepted/10.1103/PhysRevE.101.023304). A cluster analysis is performed on the accepted samples and results are saved in `res_paths['mh']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d59a0-c66e-47dc-9faf-bb226aee5130",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe86663-898e-485b-9079-acb71707f73c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ensemble=make_mcmc_ensemble(model,100, 1000,model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75035f-d681-4f52-aabd-0ad27b6e277d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Acceptance rate: {np.asarray(ensemble['accepted']).mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73983d3d-13ee-42fc-9530-a050567953d3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    " cluster_analysis(np.asarray(ensemble['x']).reshape((-1, Lf, Lf) ), model.energy, model.beta, res_paths['mh']) #U, tau |m|, tau |m|\n",
    "print(f\"Results saved at: {res_paths['mh']}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilevelTest",
   "language": "python",
   "name": "multileveltest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
