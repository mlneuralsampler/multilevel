{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ec5a5e-acd7-4f2c-a50f-cf2bf24f5c73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autograd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Ensure it points to your project root\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvan_code\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralVANMultilevel_block_wise\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvan_code\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mising\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ising_energy,analytical_solution,local_ising_energy\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvan_code\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmontecarlo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Projects/multilevelTest/van_code/nn.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvan_code\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_metrics, grab, print_metrics, make_checker_mask, save\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/multilevelTest/van_code/utils.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvan_code\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Obs\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_checker_mask\u001b[39m(shape, parity):\n\u001b[1;32m      9\u001b[0m     checker \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39muint8) \u001b[38;5;241m-\u001b[39m parity\n",
      "File \u001b[0;32m~/Projects/multilevelTest/van_code/obs.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01manp\u001b[39;00m  \u001b[38;5;66;03m# Thinly-wrapped numpy\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jacobian\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autograd'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))  # Ensure it points to your project root\n",
    "\n",
    "from van_code.nn import NeuralVANMultilevel_block_wise\n",
    "from van_code.ising import ising_energy,analytical_solution,local_ising_energy\n",
    "from van_code.montecarlo import *\n",
    "from van_code.utils import *\n",
    "from van_code.obs import Obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2864c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autograd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautograd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autograd'"
     ]
    }
   ],
   "source": [
    "import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4569e9-4b9e-4e87-871e-93d83c0511da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    default_dtype_torch=torch.float32\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'You are using device={device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164be43-0322-4b8c-ae36-a9b0b0e20310",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Model and parameters\n",
    "Our multilevel architecture uses different blocks of Autoregressive neural networks which are based on the VAN architecture by [Wu et al. (2019)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.122.080602)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f18c2f-e4e7-4a4d-81ab-153f60db5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines important parameters for the simulation\n",
    "\n",
    "Lc=2 # defines the coarser lattice\n",
    "beta=0.44 # defines the beta value (inverse of the temperature)\n",
    "\n",
    "# VAN parameters\n",
    "net_depth = 3\n",
    "net_width= 16\n",
    "half_kernel_size =6\n",
    "\n",
    "# Conditional VAN parameters\n",
    "# The i-th element of the list correspond to the parameters associated to the i-th block in the multilevel\n",
    "\n",
    "hidden_size=[[16]] * 10 # Hidden size of each CondVAN\n",
    "kernel_size=[[5,3]] * 10  # Kernel of CondVAN\n",
    "\n",
    "nlevels = 2 # Defines the number of blocks (upsamling step) in the multilevel. Every block doubles the lattice. Example: if the coarser is 2x2 after 3 levels we have 16x16\n",
    "hb_last = True # Whether to use heatbath to sample unbiased configuration from the last ARNN\n",
    "\n",
    "pretrained = True  # Wheter to use warm-restarts in training (see paper: https://openreview.net/forum?id=YcUV5apdlq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e338fe-3d49-412c-99be-d84c4f7d2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "van_hyp={\n",
    "    'net_depth':net_depth,\n",
    "    'net_width': net_width,\n",
    "    'half_kernel_size':half_kernel_size,\n",
    "    'bias':False,'z2':False,\n",
    "    'res_block':True,\n",
    "    'x_hat_clip':False,\n",
    "    'final_conv':True,\n",
    "    'epsilon':1.e-8,\n",
    "    'device':device\n",
    "}\n",
    "\n",
    "block_net_hyp={\n",
    "    'hidden_size':hidden_size,\n",
    "    'kernel_size':kernel_size,\n",
    "    'epsilon':1e-7,\n",
    "    'level':0,\n",
    "    'device':device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f246c-3856-4c65-8e2d-106364f5bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "\n",
    "model = NeuralVANMultilevel_block_wise(\n",
    "    Lc,\n",
    "    van_hyp,\n",
    "    block_net_hyp,\n",
    "    nlevels,\n",
    "    hb_last,\n",
    "    ising_energy,\n",
    "    local_ising_energy,\n",
    "    beta,\n",
    "    device\n",
    ")\n",
    "Lf = model.Lf\n",
    "#print(model)\n",
    "\n",
    "print(f'\\n\\n=======================================================================================================================================================\\n')\n",
    "print(f'You will start from coarser lattices of shape {Lc}x{Lc} and sample finer lattices of resolution {model.Lf}x{model.Lf} using {nlevels} multilevel steps.')\n",
    "print(f'\\n=======================================================================================================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989f290-fcf4-42e6-8914-e7b658d58175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default parameters for optimizer and scheduler\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.92, patience=1000, min_lr=1e-07)\n",
    "\n",
    "# Define additional training parameters. Arbitrary values can be chosen\n",
    "# the values chosen below are optimized for the purpose of this demo.\n",
    "\n",
    "bs = [16] * (nlevels+1)\n",
    "nepochs = 2 * [500] * nlevels + [500]\n",
    "print_freq = 10\n",
    "lr = 2 * [0.001] + [0.001] * (nlevels-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a949d-4642-4a59-a987-2282d0a12854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose main path to store model and logs\n",
    "main_path=''+'../data/'\n",
    "\n",
    "# Creates model identifier with corresponding params\n",
    "# '/Lf'+'_beta'+'_nblocks'+'_PCNNdepth'+'_width'+'_half_ker'+'_CCNNhs'+'_ks'\n",
    "\n",
    "model_id = f'{str(model.Lf)}_{str(beta)}_{str(nlevels)}_{str(net_depth)}_{str(net_width)}_{str(half_kernel_size)}_{str(hidden_size[0][0])}_{str(kernel_size[0])}'\n",
    "\n",
    "lc_path = main_path + 'training/' + model_id\n",
    "h_path = lc_path + '_history.log' # Path to Training history\n",
    "\n",
    "## Dict of paths to store different results\n",
    "\n",
    "res_paths = {\n",
    "    'weights': main_path+ 'model/'+ model_id +'.chckpnt', # models' weights\n",
    "    'sim' : main_path + 'results/' + model_id + '_measures.log',  # Simulations logging\n",
    "    'sim_md' : main_path + 'results/' + model_id + '_measures_modedrop.log',  # Simulations mode dropping\n",
    "    'cluster' : main_path + 'results/' + model_id + '_measuresCluster.log',  # Simulations\n",
    "    'dict_hist' : lc_path + '_historyDict.pkl',  # dictionary learning curve\n",
    "    'mh' : main_path+'results/'+ model_id +'_measuresIMH.log' # neural MCMC sampling results\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627aaeee-8aa4-41ee-a7ab-950d59d4edca",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de395c-9d62-4310-a4e6-3b55f0028563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if checkpoint exists, otherwise train a new model.\n",
    "\n",
    "if os.path.exists(res_paths['weights']):\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    print(f\"Loading model {res_paths['weights']}.\")\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    load(model, optimizer, res_paths['weights'])\n",
    "    with open(res_paths['dict_hist'], 'rb') as handle:\n",
    "        history= pickle.load(handle)\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    print(f\"Loading successful!\")\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "\n",
    "else:\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    print(f\"Nothing to load. Training of new model... \")\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "\n",
    "    history=model.train(nepochs, bs, lr, print_freq, h_path, pretrained, on_file=True)\n",
    "    save(model, optimizer, res_paths['weights'])\n",
    "    write(history, lc_path)\n",
    "\n",
    "    print(f'\\n============================================================================================================================\\n')\n",
    "    print(f\"Training successful!\")\n",
    "    print(f'\\n============================================================================================================================\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a949452-ab47-4670-9245-c646cc7b3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 10 # binning to plot training history.\n",
    "\n",
    "if history:\n",
    "    plt.plot(np.asarray(history['ESS']).reshape(int((nepochs[0]*nlevels+nepochs[-1])/bins),bins).mean(-1))\n",
    "    plt.ylabel('ESS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51a028-9e89-4544-a528-2aa80f57b118",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Analysis: Reverse Metrics\n",
    "This sections includes metrics which require samples from the model, e.g., $s\\sim q_\\theta$ where $q_\\theta$ is the autoregressive neural network.\n",
    "The resulting script `res_paths['sim']` will store:\n",
    "\n",
    "`Loss, FreeEn, ESS_rev, InternalEn, Absmag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba045204-fb9d-4fcd-bfd3-bdadcd951ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "w,E,m,t = model.sample_n_OBS(100,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ab2f7-55e3-4532-b794-7aac9e3ff4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_analysis(w, res_paths['sim']) # Stores data: Loss, FreeEn, ESS_rev\n",
    "_=gamma_analysis_OBS(E, w, res_paths['sim']) # Stores data: Internal Energy\n",
    "_=gamma_analysis_OBS(np.abs(m), w, res_paths['sim']) # Stores data: Absolute magnetization\n",
    "print(f\"Results saved at: {res_paths['sim']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975e73c-b88e-43c4-bc8c-8f03619da4ba",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Analysis: Forward metrics\n",
    "> Note to user:\n",
    "> - This only works for small lattices. As this is just a demo, configurations for larger lattices (or different $\\beta$) are not provided and users have to generate reference configurations by themselves. Once configurations are available the pipeline below can be used.\n",
    "> - Ensure to unzip the configurations before running the code below.\n",
    "\n",
    "\n",
    "This sections includes metrics which require samples from the true distribution, e.g., $s\\sim p$ where $p$ is the target Boltzmann distribution.\n",
    "Such samples can be obtained with standard methods such as the Cluster method. For the sake of this demo, configs sampled with cluster method are stored in `data/config/Ising_data_nx16_beta0.4400000000_data1000000.dat`.\n",
    "\n",
    "The script `res_paths['sim_md']` will store:\n",
    "\n",
    "`Loss_rev, FreeEn_rev, ESS_rev, Loss_fwd, FreeEn_fwd, ESS_fwd, mode_dropping_est,  InternalEn, Absmag`\n",
    "\n",
    "The script `res_paths['cluster']` will store analysis performed on samples from Cluster method, i.e., $s\\sim p$:\n",
    "\n",
    "`Loss, FreeEn, ESS_rev, InternalEn, Absmag`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005731df-a09d-4a20-b0f5-58b27a7aa453",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndat = 1000000\n",
    "path_ising = main_path + f'config/Ising_data_nx{model.Lf}_beta0.4400000000_data{ndat}.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e67ca9-7603-422e-ad35-9c313102d8a4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Loads data for 16x16\n",
    "# N.B. This might take some time.\n",
    "data = np.genfromtxt(path_ising).reshape(-1, Lf, Lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd610b06-1d9b-470c-9d5e-f4af3ad676c4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cluster_analysis(data, ising_energy, beta, res_paths['cluster']) # U, tau |m|, tau |m|\n",
    "print(f\"Results saved at: {res_paths['cluster']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb480693-5a2a-4188-8c17-7a6700b41fc6",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wf = model.sample_from_MCMC(data, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b5abf-1f37-4ddd-bc78-320de50c518e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gamma_analysis_modedrop(w, wf, res_paths['sim_md']) # Stores data: Loss, betaF, ESS, Floss, FbetaF, FESS, modedrop, U, absmag\n",
    "print(f\"Results saved at: {res_paths['sim_md']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f75ad-397a-4db0-b08c-ff0108a0445d",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "# Independent Metropolis-Hastings\n",
    "\n",
    "The cells below run Neural MCMC using a Metropolis Hastings accept-reject steps to unbias the samples drawn from the model as proposed in [Nicoli et al. Phys. Rev. E (2020)](https://link.aps.org/accepted/10.1103/PhysRevE.101.023304). A cluster analysis is performed on the accepted samples and results are saved in `res_paths['mh']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d59a0-c66e-47dc-9faf-bb226aee5130",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe86663-898e-485b-9079-acb71707f73c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ensemble=make_mcmc_ensemble(model,100, 1000,model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75035f-d681-4f52-aabd-0ad27b6e277d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Acceptance rate: {np.asarray(ensemble['accepted']).mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73983d3d-13ee-42fc-9530-a050567953d3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    " cluster_analysis(np.asarray(ensemble['x']).reshape((-1, Lf, Lf) ), model.energy, model.beta, res_paths['mh']) #U, tau |m|, tau |m|\n",
    "print(f\"Results saved at: {res_paths['mh']}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rigcs-test",
   "language": "python",
   "name": "rigcs-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
